{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Классификация изображений из датасета [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n"
      ],
      "metadata": {
        "id": "SNj1mmNDik3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 1\n",
        "\n",
        "Требования\n",
        "\n",
        "1. Используйте фреймворк [Pytorch](https://pytorch.org/)\n",
        "\n",
        "2. Не используйте предобученные модели.\n",
        "\n",
        "3. Можете загрузить готовую модель или использовать собственную архитектуру.\n",
        "\n",
        "4. Выберите способ оценки качества предсказаний модели. Обоснуйте его.\n",
        "\n",
        "5. Проведите обучение. Продемонстрируйте умение использовать соответствующие инструменты.\n",
        "\n",
        "6. Оцените полученный результат.\n",
        "\n",
        "*Не используйте инструменты принцип работы которых вам непонятен."
      ],
      "metadata": {
        "id": "Lzke8YgukOQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Загрузка библиотек\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "axhx4lNbI6PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1) Параметры\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 40\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 0.001"
      ],
      "metadata": {
        "id": "aqCO1ffYJDUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2) Работа с данными\n",
        "\n",
        "# Преобразования для данных\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std=[0.2470, 0.2435, 0.2616])\n",
        "])\n",
        "\n",
        "# Загрузка CIFAR10 и разделение на выборки\n",
        "trainset = datasets.CIFAR10(root='./data', train=True,\n",
        "                            download=True, transform=transform)\n",
        "testset = datasets.CIFAR10(root='./data', train=False,\n",
        "                           download=True, transform=transform)\n",
        "\n",
        "classes = trainset.classes\n",
        "print(classes)\n",
        "\n",
        "train_size = int(0.8 * len(trainset))\n",
        "val_size = len(trainset) - train_size\n",
        "trainset, valset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
        "\n",
        "# Создание DataLoader'ов\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                         shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(valset, batch_size=BATCH_SIZE,\n",
        "                        shuffle=False, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                        shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "1mkeQ01-JGK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0b8099-87e8-44b3-8628-de0d59b40dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3) Создание модели\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "        self.conv6 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(256)\n",
        "        self.dropout3 = nn.Dropout(0.2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
        "        self.bn7 = nn.BatchNorm1d(512)\n",
        "        self.dropout4 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = F.relu(self.bn6(self.conv6(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.bn7(self.fc1(x)))\n",
        "        x = self.dropout4(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net = Net()"
      ],
      "metadata": {
        "id": "6zcl7lJgJHuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4) Оптимизатор и функция потерь\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(net.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)"
      ],
      "metadata": {
        "id": "NywWQPQ6JJgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5) Перенос модели на GPU\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Используемое устройство: {device}\")\n",
        "\n",
        "net.to(device)"
      ],
      "metadata": {
        "id": "_zUHRuatJKv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31c530e-9eee-416d-f5e0-e1c025a583a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используемое устройство: cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout1): Dropout(p=0.2, inplace=False)\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout2): Dropout(p=0.2, inplace=False)\n",
              "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout3): Dropout(p=0.2, inplace=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
              "  (bn7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout4): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6) Обучение\n",
        "\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Обучение\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 200))\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # Валидация\n",
        "    net.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_acc = 100 * val_correct / val_total\n",
        "    print(f'Валидационная точность для эпохи {epoch+1}: {val_acc:.2f}%')\n",
        "\n",
        "    # Сохранение лучшей модели\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': net.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "        }, 'best_model.pth')\n",
        "        print('Модель сохранена!')\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_time = end_time - start_time\n",
        "    print(f'Время эпохи {epoch+1}: {epoch_time:.2f} секунд')\n",
        "\n",
        "print('Обучение завершено!')"
      ],
      "metadata": {
        "id": "0Waw3V7yJME5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80615af0-53f9-45c7-edc0-d30b8bffba9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   200] loss: 1.814\n",
            "[1,   400] loss: 1.559\n",
            "[1,   600] loss: 1.396\n",
            "[1,   800] loss: 1.294\n",
            "[1,  1000] loss: 1.218\n",
            "[1,  1200] loss: 1.149\n",
            "Валидационная точность для эпохи 1: 60.42%\n",
            "Модель сохранена!\n",
            "Время эпохи 1: 35.22 секунд\n",
            "[2,   200] loss: 1.096\n",
            "[2,   400] loss: 1.048\n",
            "[2,   600] loss: 1.008\n",
            "[2,   800] loss: 0.976\n",
            "[2,  1000] loss: 0.948\n",
            "[2,  1200] loss: 0.925\n",
            "Валидационная точность для эпохи 2: 70.18%\n",
            "Модель сохранена!\n",
            "Время эпохи 2: 36.19 секунд\n",
            "[3,   200] loss: 0.907\n",
            "[3,   400] loss: 0.862\n",
            "[3,   600] loss: 0.870\n",
            "[3,   800] loss: 0.834\n",
            "[3,  1000] loss: 0.829\n",
            "[3,  1200] loss: 0.816\n",
            "Валидационная точность для эпохи 3: 71.62%\n",
            "Модель сохранена!\n",
            "Время эпохи 3: 33.96 секунд\n",
            "[4,   200] loss: 0.786\n",
            "[4,   400] loss: 0.765\n",
            "[4,   600] loss: 0.799\n",
            "[4,   800] loss: 0.784\n",
            "[4,  1000] loss: 0.740\n",
            "[4,  1200] loss: 0.758\n",
            "Валидационная точность для эпохи 4: 76.65%\n",
            "Модель сохранена!\n",
            "Время эпохи 4: 35.37 секунд\n",
            "[5,   200] loss: 0.734\n",
            "[5,   400] loss: 0.722\n",
            "[5,   600] loss: 0.699\n",
            "[5,   800] loss: 0.697\n",
            "[5,  1000] loss: 0.680\n",
            "[5,  1200] loss: 0.649\n",
            "Валидационная точность для эпохи 5: 79.02%\n",
            "Модель сохранена!\n",
            "Время эпохи 5: 35.05 секунд\n",
            "[6,   200] loss: 0.660\n",
            "[6,   400] loss: 0.652\n",
            "[6,   600] loss: 0.679\n",
            "[6,   800] loss: 0.642\n",
            "[6,  1000] loss: 0.632\n",
            "[6,  1200] loss: 0.637\n",
            "Валидационная точность для эпохи 6: 80.31%\n",
            "Модель сохранена!\n",
            "Время эпохи 6: 33.63 секунд\n",
            "[7,   200] loss: 0.552\n",
            "[7,   400] loss: 0.581\n",
            "[7,   600] loss: 0.609\n",
            "[7,   800] loss: 0.602\n",
            "[7,  1000] loss: 0.605\n",
            "[7,  1200] loss: 0.602\n",
            "Валидационная точность для эпохи 7: 81.81%\n",
            "Модель сохранена!\n",
            "Время эпохи 7: 35.01 секунд\n",
            "[8,   200] loss: 0.556\n",
            "[8,   400] loss: 0.537\n",
            "[8,   600] loss: 0.550\n",
            "[8,   800] loss: 0.594\n",
            "[8,  1000] loss: 0.563\n",
            "[8,  1200] loss: 0.545\n",
            "Валидационная точность для эпохи 8: 84.91%\n",
            "Модель сохранена!\n",
            "Время эпохи 8: 33.52 секунд\n",
            "[9,   200] loss: 0.519\n",
            "[9,   400] loss: 0.556\n",
            "[9,   600] loss: 0.534\n",
            "[9,   800] loss: 0.519\n",
            "[9,  1000] loss: 0.506\n",
            "[9,  1200] loss: 0.519\n",
            "Валидационная точность для эпохи 9: 83.67%\n",
            "Время эпохи 9: 34.91 секунд\n",
            "[10,   200] loss: 0.525\n",
            "[10,   400] loss: 0.488\n",
            "[10,   600] loss: 0.491\n",
            "[10,   800] loss: 0.503\n",
            "[10,  1000] loss: 0.494\n",
            "[10,  1200] loss: 0.502\n",
            "Валидационная точность для эпохи 10: 84.61%\n",
            "Время эпохи 10: 35.15 секунд\n",
            "[11,   200] loss: 0.460\n",
            "[11,   400] loss: 0.477\n",
            "[11,   600] loss: 0.465\n",
            "[11,   800] loss: 0.470\n",
            "[11,  1000] loss: 0.457\n",
            "[11,  1200] loss: 0.478\n",
            "Валидационная точность для эпохи 11: 84.24%\n",
            "Время эпохи 11: 33.64 секунд\n",
            "[12,   200] loss: 0.451\n",
            "[12,   400] loss: 0.448\n",
            "[12,   600] loss: 0.450\n",
            "[12,   800] loss: 0.453\n",
            "[12,  1000] loss: 0.451\n",
            "[12,  1200] loss: 0.452\n",
            "Валидационная точность для эпохи 12: 86.58%\n",
            "Модель сохранена!\n",
            "Время эпохи 12: 35.14 секунд\n",
            "[13,   200] loss: 0.443\n",
            "[13,   400] loss: 0.419\n",
            "[13,   600] loss: 0.424\n",
            "[13,   800] loss: 0.437\n",
            "[13,  1000] loss: 0.419\n",
            "[13,  1200] loss: 0.446\n",
            "Валидационная точность для эпохи 13: 87.25%\n",
            "Модель сохранена!\n",
            "Время эпохи 13: 33.90 секунд\n",
            "[14,   200] loss: 0.413\n",
            "[14,   400] loss: 0.403\n",
            "[14,   600] loss: 0.410\n",
            "[14,   800] loss: 0.428\n",
            "[14,  1000] loss: 0.410\n",
            "[14,  1200] loss: 0.402\n",
            "Валидационная точность для эпохи 14: 87.27%\n",
            "Модель сохранена!\n",
            "Время эпохи 14: 34.71 секунд\n",
            "[15,   200] loss: 0.383\n",
            "[15,   400] loss: 0.385\n",
            "[15,   600] loss: 0.405\n",
            "[15,   800] loss: 0.407\n",
            "[15,  1000] loss: 0.412\n",
            "[15,  1200] loss: 0.391\n",
            "Валидационная точность для эпохи 15: 87.29%\n",
            "Модель сохранена!\n",
            "Время эпохи 15: 35.10 секунд\n",
            "[16,   200] loss: 0.375\n",
            "[16,   400] loss: 0.382\n",
            "[16,   600] loss: 0.379\n",
            "[16,   800] loss: 0.387\n",
            "[16,  1000] loss: 0.376\n",
            "[16,  1200] loss: 0.396\n",
            "Валидационная точность для эпохи 16: 87.69%\n",
            "Модель сохранена!\n",
            "Время эпохи 16: 33.92 секунд\n",
            "[17,   200] loss: 0.348\n",
            "[17,   400] loss: 0.393\n",
            "[17,   600] loss: 0.373\n",
            "[17,   800] loss: 0.361\n",
            "[17,  1000] loss: 0.377\n",
            "[17,  1200] loss: 0.376\n",
            "Валидационная точность для эпохи 17: 88.35%\n",
            "Модель сохранена!\n",
            "Время эпохи 17: 35.29 секунд\n",
            "[18,   200] loss: 0.331\n",
            "[18,   400] loss: 0.341\n",
            "[18,   600] loss: 0.352\n",
            "[18,   800] loss: 0.358\n",
            "[18,  1000] loss: 0.381\n",
            "[18,  1200] loss: 0.358\n",
            "Валидационная точность для эпохи 18: 88.45%\n",
            "Модель сохранена!\n",
            "Время эпохи 18: 34.94 секунд\n",
            "[19,   200] loss: 0.316\n",
            "[19,   400] loss: 0.337\n",
            "[19,   600] loss: 0.353\n",
            "[19,   800] loss: 0.343\n",
            "[19,  1000] loss: 0.350\n",
            "[19,  1200] loss: 0.363\n",
            "Валидационная точность для эпохи 19: 88.49%\n",
            "Модель сохранена!\n",
            "Время эпохи 19: 34.02 секунд\n",
            "[20,   200] loss: 0.336\n",
            "[20,   400] loss: 0.330\n",
            "[20,   600] loss: 0.322\n",
            "[20,   800] loss: 0.363\n",
            "[20,  1000] loss: 0.335\n",
            "[20,  1200] loss: 0.307\n",
            "Валидационная точность для эпохи 20: 88.92%\n",
            "Модель сохранена!\n",
            "Время эпохи 20: 35.17 секунд\n",
            "[21,   200] loss: 0.310\n",
            "[21,   400] loss: 0.317\n",
            "[21,   600] loss: 0.318\n",
            "[21,   800] loss: 0.323\n",
            "[21,  1000] loss: 0.313\n",
            "[21,  1200] loss: 0.353\n",
            "Валидационная точность для эпохи 21: 88.79%\n",
            "Время эпохи 21: 37.71 секунд\n",
            "[22,   200] loss: 0.303\n",
            "[22,   400] loss: 0.306\n",
            "[22,   600] loss: 0.303\n",
            "[22,   800] loss: 0.323\n",
            "[22,  1000] loss: 0.317\n",
            "[22,  1200] loss: 0.323\n",
            "Валидационная точность для эпохи 22: 89.11%\n",
            "Модель сохранена!\n",
            "Время эпохи 22: 35.78 секунд\n",
            "[23,   200] loss: 0.289\n",
            "[23,   400] loss: 0.289\n",
            "[23,   600] loss: 0.286\n",
            "[23,   800] loss: 0.307\n",
            "[23,  1000] loss: 0.324\n",
            "[23,  1200] loss: 0.310\n",
            "Валидационная точность для эпохи 23: 89.06%\n",
            "Время эпохи 23: 36.78 секунд\n",
            "[24,   200] loss: 0.292\n",
            "[24,   400] loss: 0.285\n",
            "[24,   600] loss: 0.275\n",
            "[24,   800] loss: 0.272\n",
            "[24,  1000] loss: 0.310\n",
            "[24,  1200] loss: 0.319\n",
            "Валидационная точность для эпохи 24: 89.40%\n",
            "Модель сохранена!\n",
            "Время эпохи 24: 37.24 секунд\n",
            "[25,   200] loss: 0.263\n",
            "[25,   400] loss: 0.288\n",
            "[25,   600] loss: 0.294\n",
            "[25,   800] loss: 0.300\n",
            "[25,  1000] loss: 0.300\n",
            "[25,  1200] loss: 0.300\n",
            "Валидационная точность для эпохи 25: 89.73%\n",
            "Модель сохранена!\n",
            "Время эпохи 25: 36.57 секунд\n",
            "[26,   200] loss: 0.280\n",
            "[26,   400] loss: 0.268\n",
            "[26,   600] loss: 0.293\n",
            "[26,   800] loss: 0.266\n",
            "[26,  1000] loss: 0.273\n",
            "[26,  1200] loss: 0.280\n",
            "Валидационная точность для эпохи 26: 89.08%\n",
            "Время эпохи 26: 35.36 секунд\n",
            "[27,   200] loss: 0.270\n",
            "[27,   400] loss: 0.275\n",
            "[27,   600] loss: 0.272\n",
            "[27,   800] loss: 0.274\n",
            "[27,  1000] loss: 0.278\n",
            "[27,  1200] loss: 0.282\n",
            "Валидационная точность для эпохи 27: 89.69%\n",
            "Время эпохи 27: 36.59 секунд\n",
            "[28,   200] loss: 0.267\n",
            "[28,   400] loss: 0.273\n",
            "[28,   600] loss: 0.262\n",
            "[28,   800] loss: 0.246\n",
            "[28,  1000] loss: 0.286\n",
            "[28,  1200] loss: 0.282\n",
            "Валидационная точность для эпохи 28: 89.44%\n",
            "Время эпохи 28: 37.09 секунд\n",
            "[29,   200] loss: 0.253\n",
            "[29,   400] loss: 0.244\n",
            "[29,   600] loss: 0.261\n",
            "[29,   800] loss: 0.256\n",
            "[29,  1000] loss: 0.264\n",
            "[29,  1200] loss: 0.281\n",
            "Валидационная точность для эпохи 29: 89.92%\n",
            "Модель сохранена!\n",
            "Время эпохи 29: 35.89 секунд\n",
            "[30,   200] loss: 0.239\n",
            "[30,   400] loss: 0.249\n",
            "[30,   600] loss: 0.254\n",
            "[30,   800] loss: 0.258\n",
            "[30,  1000] loss: 0.262\n",
            "[30,  1200] loss: 0.275\n",
            "Валидационная точность для эпохи 30: 89.96%\n",
            "Модель сохранена!\n",
            "Время эпохи 30: 35.90 секунд\n",
            "[31,   200] loss: 0.257\n",
            "[31,   400] loss: 0.254\n",
            "[31,   600] loss: 0.244\n",
            "[31,   800] loss: 0.268\n",
            "[31,  1000] loss: 0.247\n",
            "[31,  1200] loss: 0.260\n",
            "Валидационная точность для эпохи 31: 89.71%\n",
            "Время эпохи 31: 36.12 секунд\n",
            "[32,   200] loss: 0.240\n",
            "[32,   400] loss: 0.249\n",
            "[32,   600] loss: 0.251\n",
            "[32,   800] loss: 0.235\n",
            "[32,  1000] loss: 0.236\n",
            "[32,  1200] loss: 0.258\n",
            "Валидационная точность для эпохи 32: 90.28%\n",
            "Модель сохранена!\n",
            "Время эпохи 32: 35.32 секунд\n",
            "[33,   200] loss: 0.237\n",
            "[33,   400] loss: 0.233\n",
            "[33,   600] loss: 0.223\n",
            "[33,   800] loss: 0.230\n",
            "[33,  1000] loss: 0.251\n",
            "[33,  1200] loss: 0.253\n",
            "Валидационная точность для эпохи 33: 89.86%\n",
            "Время эпохи 33: 35.49 секунд\n",
            "[34,   200] loss: 0.231\n",
            "[34,   400] loss: 0.233\n",
            "[34,   600] loss: 0.237\n",
            "[34,   800] loss: 0.247\n",
            "[34,  1000] loss: 0.235\n",
            "[34,  1200] loss: 0.237\n",
            "Валидационная точность для эпохи 34: 89.59%\n",
            "Время эпохи 34: 36.08 секунд\n",
            "[35,   200] loss: 0.210\n",
            "[35,   400] loss: 0.219\n",
            "[35,   600] loss: 0.230\n",
            "[35,   800] loss: 0.225\n",
            "[35,  1000] loss: 0.250\n",
            "[35,  1200] loss: 0.234\n",
            "Валидационная точность для эпохи 35: 90.35%\n",
            "Модель сохранена!\n",
            "Время эпохи 35: 35.72 секунд\n",
            "[36,   200] loss: 0.228\n",
            "[36,   400] loss: 0.234\n",
            "[36,   600] loss: 0.222\n",
            "[36,   800] loss: 0.215\n",
            "[36,  1000] loss: 0.222\n",
            "[36,  1200] loss: 0.233\n",
            "Валидационная точность для эпохи 36: 90.49%\n",
            "Модель сохранена!\n",
            "Время эпохи 36: 34.60 секунд\n",
            "[37,   200] loss: 0.223\n",
            "[37,   400] loss: 0.220\n",
            "[37,   600] loss: 0.227\n",
            "[37,   800] loss: 0.228\n",
            "[37,  1000] loss: 0.224\n",
            "[37,  1200] loss: 0.234\n",
            "Валидационная точность для эпохи 37: 90.57%\n",
            "Модель сохранена!\n",
            "Время эпохи 37: 36.34 секунд\n",
            "[38,   200] loss: 0.205\n",
            "[38,   400] loss: 0.226\n",
            "[38,   600] loss: 0.212\n",
            "[38,   800] loss: 0.220\n",
            "[38,  1000] loss: 0.221\n",
            "[38,  1200] loss: 0.225\n",
            "Валидационная точность для эпохи 38: 90.23%\n",
            "Время эпохи 38: 36.24 секунд\n",
            "[39,   200] loss: 0.206\n",
            "[39,   400] loss: 0.221\n",
            "[39,   600] loss: 0.217\n",
            "[39,   800] loss: 0.221\n",
            "[39,  1000] loss: 0.217\n",
            "[39,  1200] loss: 0.225\n",
            "Валидационная точность для эпохи 39: 90.78%\n",
            "Модель сохранена!\n",
            "Время эпохи 39: 34.97 секунд\n",
            "[40,   200] loss: 0.191\n",
            "[40,   400] loss: 0.209\n",
            "[40,   600] loss: 0.237\n",
            "[40,   800] loss: 0.211\n",
            "[40,  1000] loss: 0.221\n",
            "[40,  1200] loss: 0.217\n",
            "Валидационная точность для эпохи 40: 90.36%\n",
            "Время эпохи 40: 36.08 секунд\n",
            "Обучение завершено!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7) Тестирование модели\n",
        "\n",
        "# Загрузка лучшей модели\n",
        "checkpoint = torch.load('best_model.pth')\n",
        "net.load_state_dict(checkpoint['model_state_dict'])\n",
        "net.to(device)\n",
        "net.eval()\n",
        "\n",
        "# Общая точность\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f}%')\n",
        "\n",
        "# Точность для каждого класса\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
      ],
      "metadata": {
        "id": "uDV0EFBNJOgO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2115013c-f40e-4942-e114-f27714672924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 89.99%\n",
            "Accuracy of airplane : 90 %\n",
            "Accuracy of automobile : 93 %\n",
            "Accuracy of  bird : 82 %\n",
            "Accuracy of   cat : 79 %\n",
            "Accuracy of  deer : 88 %\n",
            "Accuracy of   dog : 84 %\n",
            "Accuracy of  frog : 95 %\n",
            "Accuracy of horse : 90 %\n",
            "Accuracy of  ship : 95 %\n",
            "Accuracy of truck : 95 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 2"
      ],
      "metadata": {
        "id": "Po8kgAHAZ9KN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Загрузка библиотек\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.models import resnet50\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "h6FvaN49H4Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1) Параметры\n",
        "\n",
        "batch_size = 64\n",
        "learning_rate = 1e-4\n",
        "num_epochs = 10\n",
        "img_size = 128\n",
        "random_seed = 42"
      ],
      "metadata": {
        "id": "xC15dsDPIS0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed)\n",
        "torch.use_deterministic_algorithms(False)\n",
        "\n",
        "current_seed = torch.initial_seed()\n",
        "print(f\"Текущий seed: {current_seed}\")"
      ],
      "metadata": {
        "id": "jdl7SKZtITH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b3c58a-b643-45d6-ed20-9572a35eb4d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текущий seed: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2) Работа с данными\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True,\n",
        "                                transform=train_transforms, download=True)\n",
        "\n",
        "classes = train_dataset.classes\n",
        "print(classes)\n",
        "\n",
        "valid_dataset = datasets.CIFAR10(root='./data', train=False,\n",
        "                                transform=test_transforms, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "kvOXeMfLIUSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd55daad-c78d-4822-9d38-22d6429726a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3) Создание модели и перенос на GPU\n",
        "\n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNet50, self).__init__()\n",
        "        self.model = resnet50(weights=\"DEFAULT\")\n",
        "        self.in_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(self.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = ResNet50(num_classes=10).to(device)"
      ],
      "metadata": {
        "id": "Q_sy_Y59IV04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f81c14-2659-4760-bc83-a8c2da4c44f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:02<00:00, 47.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4) Оптимизатор, функция потерь и планировщик\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
      ],
      "metadata": {
        "id": "7B4VtE7aIXqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5) Обучение\n",
        "\n",
        "best_epoch = 0\n",
        "best_acc = 0.0\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Обучение\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    epoch_corrects = 0\n",
        "    for batch_in, batch_out in tqdm(train_loader):\n",
        "        batch_in = batch_in.to(device)\n",
        "        batch_out = batch_out.to(device)\n",
        "\n",
        "        y_pred = model(batch_in)\n",
        "        preds = torch.argmax(y_pred, 1)\n",
        "        loss = criterion(y_pred, batch_out)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item() * batch_in.size(0)\n",
        "        epoch_corrects += torch.sum(preds == batch_out.data)\n",
        "\n",
        "    epoch_loss = epoch_loss / len(train_loader.dataset)\n",
        "    epoch_acc = epoch_corrects / len(train_loader.dataset)\n",
        "    print(f\"Train loss: {epoch_loss:.4f}\")\n",
        "    print(f\"Train acc: {epoch_acc:.4f}\")\n",
        "\n",
        "    # Валидация\n",
        "    model.eval()\n",
        "    epoch_loss = 0.0\n",
        "    epoch_corrects = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_in, batch_out in tqdm(valid_loader):\n",
        "            batch_in = batch_in.to(device)\n",
        "            batch_out = batch_out.to(device)\n",
        "\n",
        "            y_pred = model(batch_in)\n",
        "            preds = torch.argmax(y_pred, 1)\n",
        "            loss = criterion(y_pred, batch_out)\n",
        "\n",
        "            epoch_loss += loss.item() * batch_in.size(0)\n",
        "            epoch_corrects += torch.sum(preds == batch_out.data)\n",
        "\n",
        "    epoch_loss = epoch_loss / len(valid_loader.dataset)\n",
        "    epoch_acc = epoch_corrects / len(valid_loader.dataset)\n",
        "\n",
        "    # Обновление планировщика\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Valid loss: {epoch_loss:.4f}\")\n",
        "    print(f\"Valid acc: {epoch_acc:.4f}\")\n",
        "\n",
        "    # Сохранение лучшей модели\n",
        "    if epoch_acc >= best_acc:\n",
        "        best_epoch = epoch\n",
        "        best_acc = epoch_acc\n",
        "        torch.save(model, \"./model2.pt\")\n",
        "\n",
        "    print(f\"Best epoch: {best_epoch}\")\n",
        "    print(f\"Best acc: {best_acc:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_time = end_time - start_time\n",
        "    print(f'Время эпохи {epoch}: {epoch_time:.2f} секунд')\n",
        "\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "0Jf-0xsgIabS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81d9dd8-fd05-4b27-cdb9-a7ece75250be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [03:28<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.3419\n",
            "Train acc: 0.8938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:16<00:00,  9.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.1264\n",
            "Valid acc: 0.9571\n",
            "Best epoch: 1\n",
            "Best acc: 0.9571\n",
            "Время эпохи 1: 224.89 секунд\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [03:27<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.1300\n",
            "Train acc: 0.9559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:16<00:00,  9.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.1114\n",
            "Valid acc: 0.9631\n",
            "Best epoch: 2\n",
            "Best acc: 0.9631\n",
            "Время эпохи 2: 224.06 секунд\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "Epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [03:28<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.0893\n",
            "Train acc: 0.9697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:15<00:00,  9.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.1112\n",
            "Valid acc: 0.9621\n",
            "Best epoch: 2\n",
            "Best acc: 0.9631\n",
            "Время эпохи 3: 224.80 секунд\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "Epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [03:28<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.0675\n",
            "Train acc: 0.9767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:15<00:00,  9.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.1049\n",
            "Valid acc: 0.9656\n",
            "Best epoch: 4\n",
            "Best acc: 0.9656\n",
            "Время эпохи 4: 224.75 секунд\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "Epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [03:29<00:00,  3.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.0557\n",
            "Train acc: 0.9806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:16<00:00,  9.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.1138\n",
            "Valid acc: 0.9648\n",
            "Best epoch: 4\n",
            "Best acc: 0.9656\n",
            "Время эпохи 5: 225.44 секунд\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "Epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [03:30<00:00,  3.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.0307\n",
            "Train acc: 0.9901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:16<00:00,  9.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.0996\n",
            "Valid acc: 0.9700\n",
            "Best epoch: 6\n",
            "Best acc: 0.9700\n",
            "Время эпохи 6: 227.16 секунд\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "Epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [03:32<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.0196\n",
            "Train acc: 0.9937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:17<00:00,  8.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.1042\n",
            "Valid acc: 0.9698\n",
            "Best epoch: 6\n",
            "Best acc: 0.9700\n",
            "Время эпохи 7: 229.93 секунд\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "Epoch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [03:36<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.0209\n",
            "Train acc: 0.9933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:18<00:00,  8.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.1029\n",
            "Valid acc: 0.9723\n",
            "Best epoch: 8\n",
            "Best acc: 0.9723\n",
            "Время эпохи 8: 235.05 секунд\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "Epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [03:36<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.0176\n",
            "Train acc: 0.9942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:18<00:00,  8.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.1077\n",
            "Valid acc: 0.9719\n",
            "Best epoch: 8\n",
            "Best acc: 0.9723\n",
            "Время эпохи 9: 235.28 секунд\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "Epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [03:36<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.0174\n",
            "Train acc: 0.9942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:16<00:00,  9.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.1113\n",
            "Valid acc: 0.9705\n",
            "Best epoch: 8\n",
            "Best acc: 0.9723\n",
            "Время эпохи 10: 233.27 секунд\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6) Тестирование модели\n",
        "\n",
        "# Загружаем лучшую модель\n",
        "model = torch.load(\"./model2.pt\")\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "QHW58M3NIcQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0069d3b2-d3c6-4ecb-9391-ce42d4aa7461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet50(\n",
              "  (model): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Общая точность\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(valid_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f}%')\n",
        "\n",
        "\n",
        "# Точность для каждого класса\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(valid_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "XwcehJjTIeSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b345b922-73fc-4ec1-d8dd-abe7d930186a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:17<00:00,  9.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:17<00:00,  9.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of airplane : 98 %\n",
            "Accuracy of automobile : 98 %\n",
            "Accuracy of  bird : 96 %\n",
            "Accuracy of   cat : 95 %\n",
            "Accuracy of  deer : 96 %\n",
            "Accuracy of   dog : 95 %\n",
            "Accuracy of  frog : 98 %\n",
            "Accuracy of horse : 98 %\n",
            "Accuracy of  ship : 98 %\n",
            "Accuracy of truck : 96 %\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вывод\n"
      ],
      "metadata": {
        "id": "O28yk5z1lsIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сравнительный анализ результатов:**\n",
        "\n",
        "- Результаты модели без предобученных весов:\n",
        "\n",
        " -Точность на тестовом наборе: 89.99% +- 0.2\n",
        "\n",
        " -Время обучения: 1353.17 сек или 22.55 мин.\n",
        "\n",
        "- Результаты модели с использованием предобученной ResNet50:\n",
        "\n",
        " -Точность на тестовом наборе: 97.23% +- 0.2\n",
        "\n",
        " -Время обучения: 2340.63 сек или 39 мин\n",
        "\n",
        "**Вывод:**\n",
        "\n",
        "Модель с использованием предобученной ResNet50 показала более высокую точность на тестовом наборе. Это связано с тем, что предобученная модель уже содержит знания о визуальных особенностях, полученные на большом наборе данных ImageNet. Также она обучилась быстрее, если смотреть по эпохам - в целом, достаточно было сократить количество эпох до 5.\n",
        "\n",
        "Кроме того, предобученная модель обладает очень хорошей общей производительностью и способна эффективно классифицировать большинство объектов из этого набора данных, что отлично видно на точности по классам.\n",
        "\n",
        "Подытожив, можно сказать, что в некоторых случаях не стоит изобретать велосипед. Использование предобученных моделей, таких как ResNet50, может быть более эффективным и результативным, чем разработка собственной модели с нуля."
      ],
      "metadata": {
        "id": "ZHwni1Gi25Eu"
      }
    }
  ]
}